{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b92c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fdfed37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting diffusers[training]==0.2.3\n",
      "  Downloading diffusers-0.2.3-py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (3.7.1)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (1.13.0a0+08820cb)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (4.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (2022.6.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (0.16.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (1.22.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (9.0.1)\n",
      "Collecting modelcards\n",
      "  Downloading modelcards-0.1.6-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.8/site-packages (from diffusers[training]==0.2.3) (2.9.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "\u001b[K     |████████████████████████████████| 519 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "\u001b[K     |████████████████████████████████| 258 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->diffusers[training]==0.2.3) (4.64.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->diffusers[training]==0.2.3) (2022.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->diffusers[training]==0.2.3) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->diffusers[training]==0.2.3) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->diffusers[training]==0.2.3) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.8.1->diffusers[training]==0.2.3) (3.0.9)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate->diffusers[training]==0.2.3) (5.9.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-13.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.1 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]<2023.9.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[K     |████████████████████████████████| 163 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.8,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->diffusers[training]==0.2.3) (1.4.3)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->diffusers[training]==0.2.3) (2.0.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->diffusers[training]==0.2.3) (21.4.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "\u001b[K     |████████████████████████████████| 266 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers[training]==0.2.3) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers[training]==0.2.3) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->diffusers[training]==0.2.3) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata->diffusers[training]==0.2.3) (3.8.0)\n",
      "Requirement already satisfied: Jinja2 in /opt/conda/lib/python3.8/site-packages (from modelcards->diffusers[training]==0.2.3) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from Jinja2->modelcards->diffusers[training]==0.2.3) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->diffusers[training]==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->diffusers[training]==0.2.3) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets->diffusers[training]==0.2.3) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (3.3.7)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (1.47.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (59.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (0.4.6)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard->diffusers[training]==0.2.3) (2.9.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.2.3) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.2.3) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.2.3) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->diffusers[training]==0.2.3) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->diffusers[training]==0.2.3) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->diffusers[training]==0.2.3) (3.2.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, fsspec, dill, aiohttp, xxhash, pyarrow, protobuf, multiprocess, modelcards, diffusers, datasets, accelerate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.5.0\n",
      "    Uninstalling fsspec-2022.5.0:\n",
      "      Successfully uninstalled fsspec-2022.5.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 7.0.0\n",
      "    Uninstalling pyarrow-7.0.0:\n",
      "      Successfully uninstalled pyarrow-7.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 22.6.0a0+319.g97422602b8 requires protobuf<3.21.0a0,>=3.20.1, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\n",
      "Successfully installed accelerate-0.23.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.14.5 diffusers-0.2.3 dill-0.3.7 frozenlist-1.4.0 fsspec-2023.6.0 modelcards-0.1.6 multidict-6.0.4 multiprocess-0.70.15 protobuf-3.19.6 pyarrow-13.0.0 xxhash-3.3.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers[training]==0.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28797558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f13c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: 2*(x-0.5))\n",
    "    #transforms.Lambda(lambda x: x*2 - 1)\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 1024\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "674d9157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show example\n",
    "for i in train_loader:\n",
    "  x, y = i\n",
    "  plt.imshow(x[1][0], cmap='Greys_r', interpolation='nearest')\n",
    "  plt.axis('off')\n",
    "  plt.title(y[1].numpy())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "386613b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffusers\n",
    "model = diffusers.UNet2DModel(\n",
    "    sample_size=28,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128,128,256,512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b96de195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1024, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print('Output shape:', model(x, timestep=0)[\"sample\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2437811",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9834006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFlowNetwork2D(nn.Module):\n",
    "    def __init__(self, net, D, sigma=0.001, tmin=1e-10, xmin=-1, xmax=1):\n",
    "        super(BayesianFlowNetwork2D, self).__init__()\n",
    "        self.sigma = torch.tensor(sigma)\n",
    "        self.D = D\n",
    "        self.t_min = tmin\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, mu, t, ema):\n",
    "        if ema is not None:\n",
    "          with ema.average_parameters():\n",
    "            output = self.net(mu,t)['sample']  # (B, D, D, K)\n",
    "        else:\n",
    "          output = self.net(mu,t)['sample']  # (B, D, D, K)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def CTS_OUTPUT_PREDICTION(self, mu, t, gamma,ema=None):\n",
    "        eps_hat = self.forward(mu, t, ema=ema)\n",
    "        mask = t>=self.t_min\n",
    "        eps_hat = eps_hat*mask[:,None,None,None]\n",
    "        x_hat = (mu/gamma[:, None, None, None]) - ((1-gamma[:, None, None, None])/gamma[:, None, None, None]).sqrt()*eps_hat\n",
    "        x_hat = torch.clip(x_hat,self.xmin,self.xmax)\n",
    "        return x_hat\n",
    "\n",
    "    def process(self, x, t=None, training=True):\n",
    "\n",
    "        # Step 1: Sample t from U(0, 1)\n",
    "        if t is None:\n",
    "          t = torch.rand((x.size(0),), device=x.device, dtype=torch.float32)\n",
    "        else:\n",
    "          t = torch.tensor(t, device=x.device, dtype=torch.float32)[None]\n",
    "\n",
    "        # Step 2: Calculate gamma\n",
    "        gamma = 1- self.sigma**(2*t)  # (B,\n",
    "\n",
    "\n",
    "        # Step 3: Sample mu from N(gamma*X, gamma*(1-gamma)*I)\n",
    "        mean = gamma[:, None, None, None] * (x)\n",
    "        std = gamma*(1-gamma)\n",
    "        eps = torch.randn_like(mean)\n",
    "        mu = mean + std[:, None, None, None] * eps\n",
    "\n",
    "        # Step 5: CTS_OUTPUT_PREDICTION\n",
    "        x_hat = self.CTS_OUTPUT_PREDICTION(mu, t, gamma)  # (B, K, D, D)\n",
    "       \n",
    "\n",
    "        L_infinity = -torch.log(self.sigma)*(self.sigma**(-2*t[:, None, None, None]))*((x - x_hat) ** 2)\n",
    "\n",
    "        if training:\n",
    "          return L_infinity.mean()\n",
    "        else:\n",
    "           return L_infinity.mean(), mu, t\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(self, batch_size=128, nb_steps=10, ema=None, device='cpu'):\n",
    "        self.eval()\n",
    "        mu = torch.zeros((batch_size, 1, self.D, self.D), device=device)\n",
    "        rho = 1\n",
    "\n",
    "        for i in tqdm(range(1, nb_steps+1)):\n",
    "            t = (i-1) / nb_steps\n",
    "            if t<1e-7:\n",
    "              t+=1e-7\n",
    "            t = t * torch.ones((mu.shape[0]), device=mu.device, dtype=mu.dtype)\n",
    "\n",
    "            x_hat = self.CTS_OUTPUT_PREDICTION(mu, t, 1- self.sigma**(2*t))  # (B, D, D, K)\n",
    "            alpha = (self.sigma**((-2 * i)/nb_steps))*(1-self.sigma**(2/nb_steps))\n",
    "            std = 1/alpha\n",
    "            eps = torch.randn_like(x_hat)\n",
    "            y = x_hat + std * eps  # (B, D, D, K)\n",
    "\n",
    "            mu = (rho*mu + alpha*y)/(rho+alpha)\n",
    "            rho = rho+alpha\n",
    "        t_final = torch.ones((mu.shape[0]), device=mu.device, dtype=mu.dtype)\n",
    "        x_hat = self.CTS_OUTPUT_PREDICTION(mu, t_final, 1- self.sigma**(2*t_final))\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac41e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "bfn = BayesianFlowNetwork2D(model, 32)\n",
    "#bfn = MyUNet()\n",
    "#ema = torch_ema.ExponentialMovingAverage(bfn.net.parameters(), decay=0.9999)\n",
    "\n",
    "bfn.cuda()\n",
    "#ema.to(device)\n",
    "\n",
    "optim = AdamW(bfn.parameters(), lr=0.0002, betas=(0.9, 0.98), weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98648051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:   2%|██                                                                                                                      | 1/59 [00:00<00:47,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8961, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 59/59 [00:42<00:00,  1.38it/s]\n",
      "Epoch 2/1000: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 59/59 [00:42<00:00,  1.39it/s]\n",
      "Epoch 3/1000: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 59/59 [00:42<00:00,  1.38it/s]\n",
      "Epoch 4/1000:  46%|██████████████████████████████████████████████████████▍                                                                | 27/59 [00:20<00:24,  1.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m bfn\u001b[38;5;241m.\u001b[39mprocess(X\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:401\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    394\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    395\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    400\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 401\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "epochs = 1000\n",
    "best_loss = 10000\n",
    "k = 0\n",
    "early_stopping = False\n",
    "patience = 1e6\n",
    "J = 0\n",
    "for i in range(epochs):\n",
    "  for X, _ in tqdm(train_loader, desc=f\"Epoch {i+1}/{epochs}\"):\n",
    "      optim.zero_grad()\n",
    "\n",
    "      loss = bfn.process(X.to(device))\n",
    "      loss.backward()\n",
    "\n",
    "      optim.step()\n",
    "\n",
    "      losses.append(loss.item())\n",
    "\n",
    "      if J%1000 == 0:\n",
    "        print(loss)\n",
    "      J+=1\n",
    "\n",
    "      if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        k = 0\n",
    "      else:\n",
    "        k += 1\n",
    "        if k == patience:\n",
    "          k = 0\n",
    "          early_stopping = True\n",
    "          break\n",
    "  if early_stopping:\n",
    "    break\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d7dc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def moving_average(data, window_size):\n",
    "    moving_avg = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        window = data[i : i + window_size]\n",
    "        avg = sum(window) / window_size\n",
    "        moving_avg.append(avg)\n",
    "    return moving_avg\n",
    "\n",
    "plt.plot(moving_average(losses, 20))\n",
    "plt.ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d55840c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 66.05it/s]\n"
     ]
    }
   ],
   "source": [
    "x_hat = bfn.sample(device='cuda', nb_steps=1000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f142d7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 4, figsize=(8, 8),  layout='constrained')\n",
    "\n",
    "for i in range(16):\n",
    "    ax[i // 4, i % 4].imshow(x_hat.cpu().numpy()[i][0], cmap='Greys_r')\n",
    "    ax[i // 4, i % 4].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c4b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c0b85ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([218, 782, 803])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa7200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
